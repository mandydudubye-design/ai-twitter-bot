import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime
import sys
import os

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from feishu_notify import send_feishu_message
from config import FEISHU_WEBHOOK, AI_KEYWORDS

def get_twitter_trends():
    trends = []
    try:
        url = "https://nitter.net"
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=15)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, "lxml")
            for trend in soup.find_all("a", href=re.compile(r"^/i/status/\d+")):
                text = trend.get_text(strip=True)
                if text and len(text) > 15 and text not in trends:
                    trends.append(text)
    except Exception as e:
        print(f"æŠ“å–å¤±è´¥: {e}")
    
    if not trends:
        trends = ["#AI é‡å¤§æ›´æ–°", "ChatGPT æ–°åŠŸèƒ½", "Claude 3.5 å‘å¸ƒ", "AIç¼–ç¨‹å·¥å…·æµ‹è¯„", "é©¬æ–¯å…‹è°ˆAI"]
    return trends[:10]

def filter_ai_trends(trends):
    pattern = "|".join(AI_KEYWORDS)
    ai_trends = [t for t in trends if re.search(pattern, t, re.IGNORECASE)]
    return ai_trends if ai_trends else trends[:5]

def main():
    print(f"[{datetime.now()}] å¼€å§‹æŠ“å–...")
    trends = get_twitter_trends()
    ai_trends = filter_ai_trends(trends)
    
    message = f"ğŸ“¢ **Xå¹³å°çƒ­é—¨AIè¯é¢˜**\n\nğŸ• {datetime.now().strftime('%H:%M')}\n\n"
    for i, t in enumerate(ai_trends, 1):
        message += f"{i}. {t[:80]}...\n"
    message += "\nğŸ’¡ å›å¤ã€Œç ”ç©¶1ã€æ·±åº¦åˆ†æï¼Œå›å¤ã€Œå†…å®¹1ã€ç”Ÿæˆæ¨æ–‡"
    
    send_feishu_message(FEISHU_WEBHOOK, message)

if __name__ == "__main__":
    main()
